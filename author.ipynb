{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorship attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Instructions on how to get the \"Fifty Victorian Era Novelists Authorship Attribution Data\" dataset can be found:\n",
    "https://github.com/agungor2/Authorship_Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/Gungor_2018_VictorianAuthorAttribution_data-train.csv\", encoding = \"ISO-8859-1\", error_bad_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ou have time to listen i will give you the ent...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wish for solitude he was twenty years of age a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and the skirt blew in perfect freedom about th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of san and the rows of shops opposite impresse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an hour s walk was as tiresome as three in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53673</th>\n",
       "      <td>after surrounding and searching the whole plac...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53674</th>\n",
       "      <td>giant who could make a young earthquake or a w...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53675</th>\n",
       "      <td>waters of the lake at the bottom of the hill c...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53676</th>\n",
       "      <td>fingers and thumb in it exactly as it came out...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53677</th>\n",
       "      <td>giant s sake he won t meet with for if he does...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53678 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "0      ou have time to listen i will give you the ent...       1\n",
       "1      wish for solitude he was twenty years of age a...       1\n",
       "2      and the skirt blew in perfect freedom about th...       1\n",
       "3      of san and the rows of shops opposite impresse...       1\n",
       "4      an hour s walk was as tiresome as three in a s...       1\n",
       "...                                                  ...     ...\n",
       "53673  after surrounding and searching the whole plac...      50\n",
       "53674  giant who could make a young earthquake or a w...      50\n",
       "53675  waters of the lake at the bottom of the hill c...      50\n",
       "53676  fingers and thumb in it exactly as it came out...      50\n",
       "53677  giant s sake he won t meet with for if he does...      50\n",
       "\n",
       "[53678 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ou have time to listen i will give you the ent...\n",
       "1        wish for solitude he was twenty years of age a...\n",
       "2        and the skirt blew in perfect freedom about th...\n",
       "3        of san and the rows of shops opposite impresse...\n",
       "4        an hour s walk was as tiresome as three in a s...\n",
       "                               ...                        \n",
       "53673    after surrounding and searching the whole plac...\n",
       "53674    giant who could make a young earthquake or a w...\n",
       "53675    waters of the lake at the bottom of the hill c...\n",
       "53676    fingers and thumb in it exactly as it came out...\n",
       "53677    giant s sake he won t meet with for if he does...\n",
       "Name: text, Length: 53678, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into random train and test subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['author']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42944    fresh and we go down below and drive very fast...\n",
       "17703    stop here not stop here â eh eh we must tell â...\n",
       "13133    bowl you shall know â mrs told me and how did ...\n",
       "33289    tell you more than my lips could possibly do s...\n",
       "13992    i when he s all o thee i can get sight on come...\n",
       "                               ...                        \n",
       "45891    from belonged to the and order of and they pro...\n",
       "52416    there were little knots of authors who lived w...\n",
       "42613    i felt myself that if this unhappy animal had ...\n",
       "43567    she tow iâ she tow i yon s her night signal sh...\n",
       "2732     foot on the yes said i while jim burst out lau...\n",
       "Name: text, Length: 35964, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42944    39\n",
       "17703    15\n",
       "13133    12\n",
       "33289    30\n",
       "13992    14\n",
       "         ..\n",
       "45891    42\n",
       "52416    48\n",
       "42613    39\n",
       "43567    39\n",
       "2732      4\n",
       "Name: author, Length: 35964, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning the text content into numerical feature vectors\n",
    "(The Bag of Words representation)\n",
    "\n",
    "A corpus of documents can be represented by a matrix with one row per document and one column per token (e.g. word) occurring in the corpus.  \n",
    "More information: https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "CountVectorizer converts a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35964, 9972)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index value of a word in the vocabulary is linked to its frequency in the whole training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.vocabulary_.get(u'author'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some improvements:\n",
    "\n",
    "1. We can divide the number of occurrences of each word in a document by the total number of words in the document (because longer documents will have higher average count values than shorter documents, even though they might talk about the same topics). We will get **tf**.\n",
    "\n",
    "2. After getting **tf** we can downscale weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus. We will get **tf–idf**.\n",
    "\n",
    "**tf** - Term Frequencies  \n",
    "**tf–idf** - Term Frequency times Inverse Document Frequency\n",
    "\n",
    "TfidfTransformer transforms a count matrix to a normalized tf or tf-idf representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35964, 9972)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 769 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from test data\n",
    "We call transform() instead of fit_transform(), because features have already been fit to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 294 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_predicted = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4706446878175454"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_predicted == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       307\n",
      "           2       0.00      0.00      0.00       116\n",
      "           3       0.00      0.00      0.00        71\n",
      "           4       0.91      0.11      0.19       496\n",
      "           6       0.00      0.00      0.00       139\n",
      "           8       0.25      0.98      0.39      2297\n",
      "           9       1.00      0.01      0.02       384\n",
      "          10       0.00      0.00      0.00       262\n",
      "          11       1.00      0.01      0.02       127\n",
      "          12       0.00      0.00      0.00       206\n",
      "          13       0.00      0.00      0.00       143\n",
      "          14       0.84      0.52      0.64       858\n",
      "          15       1.00      0.21      0.35       489\n",
      "          16       0.00      0.00      0.00        63\n",
      "          17       0.00      0.00      0.00       210\n",
      "          18       1.00      0.06      0.10       361\n",
      "          19       0.80      0.74      0.77       504\n",
      "          20       1.00      0.23      0.37       189\n",
      "          21       0.68      0.78      0.73       750\n",
      "          22       0.00      0.00      0.00       163\n",
      "          23       0.00      0.00      0.00       161\n",
      "          24       0.00      0.00      0.00       127\n",
      "          25       0.50      0.01      0.02       384\n",
      "          26       0.77      0.99      0.87      1447\n",
      "          27       0.00      0.00      0.00       106\n",
      "          28       0.86      0.65      0.74       265\n",
      "          29       1.00      0.01      0.01       200\n",
      "          30       1.00      0.00      0.01       330\n",
      "          32       0.50      0.03      0.06       241\n",
      "          33       0.95      0.47      0.63       583\n",
      "          34       0.00      0.00      0.00       134\n",
      "          35       0.00      0.00      0.00       251\n",
      "          36       1.00      0.09      0.16       219\n",
      "          37       0.41      0.90      0.56       803\n",
      "          38       0.95      0.15      0.26       393\n",
      "          39       0.73      0.84      0.78       746\n",
      "          40       0.00      0.00      0.00       146\n",
      "          41       1.00      0.01      0.01       306\n",
      "          42       1.00      0.53      0.69       337\n",
      "          43       1.00      0.50      0.67       406\n",
      "          44       0.00      0.00      0.00       139\n",
      "          45       0.66      0.40      0.50       753\n",
      "          46       1.00      0.14      0.24       192\n",
      "          48       0.76      0.73      0.74       599\n",
      "          50       1.00      0.00      0.01       311\n",
      "\n",
      "    accuracy                           0.47     17714\n",
      "   macro avg       0.52      0.22      0.23     17714\n",
      "weighted avg       0.62      0.47      0.40     17714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true=y_test, y_pred=y_predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.confusion_matrix(y_true=y_test, y_pred=y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "SGDClassifier  \n",
    "Linear classifiers (SVM, logistic regression, etc.) with SGD (stochastic gradient descent) training.  \n",
    "loss='hinge' gives a linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, max_iter=5, random_state=0, tol=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf2 = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=0, max_iter=5, tol=None)\n",
    "clf2.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 326 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_predicted2 = clf2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.809021113243762"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_predicted2  == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.87      0.92       307\n",
      "           2       1.00      0.13      0.23       116\n",
      "           3       0.91      0.14      0.24        71\n",
      "           4       0.92      0.69      0.79       496\n",
      "           6       1.00      0.04      0.08       139\n",
      "           8       0.68      0.94      0.79      2297\n",
      "           9       0.94      0.79      0.86       384\n",
      "          10       0.98      0.76      0.86       262\n",
      "          11       0.82      0.59      0.69       127\n",
      "          12       0.99      0.75      0.85       206\n",
      "          13       0.97      0.55      0.70       143\n",
      "          14       0.83      0.79      0.81       858\n",
      "          15       0.90      0.92      0.91       489\n",
      "          16       0.00      0.00      0.00        63\n",
      "          17       0.98      0.50      0.67       210\n",
      "          18       0.94      0.89      0.92       361\n",
      "          19       0.81      0.90      0.85       504\n",
      "          20       0.98      0.90      0.94       189\n",
      "          21       0.84      0.92      0.88       750\n",
      "          22       0.99      0.67      0.80       163\n",
      "          23       0.93      0.24      0.38       161\n",
      "          24       0.98      0.49      0.65       127\n",
      "          25       0.94      0.60      0.74       384\n",
      "          26       0.68      1.00      0.81      1447\n",
      "          27       0.98      0.44      0.61       106\n",
      "          28       0.81      0.85      0.83       265\n",
      "          29       0.92      0.72      0.81       200\n",
      "          30       0.95      0.81      0.87       330\n",
      "          32       0.89      0.71      0.79       241\n",
      "          33       0.79      0.92      0.85       583\n",
      "          34       0.96      0.66      0.78       134\n",
      "          35       0.97      0.39      0.55       251\n",
      "          36       0.93      0.89      0.91       219\n",
      "          37       0.75      0.85      0.80       803\n",
      "          38       0.90      0.72      0.80       393\n",
      "          39       0.81      0.93      0.87       746\n",
      "          40       0.97      0.62      0.75       146\n",
      "          41       0.88      0.56      0.68       306\n",
      "          42       0.92      0.96      0.94       337\n",
      "          43       0.88      0.95      0.91       406\n",
      "          44       1.00      0.36      0.53       139\n",
      "          45       0.82      0.86      0.84       753\n",
      "          46       0.88      0.49      0.63       192\n",
      "          48       0.77      0.90      0.83       599\n",
      "          50       0.87      0.77      0.82       311\n",
      "\n",
      "    accuracy                           0.81     17714\n",
      "   macro avg       0.88      0.68      0.73     17714\n",
      "weighted avg       0.83      0.81      0.80     17714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true=y_test, y_pred=y_predicted2, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.confusion_matrix(y_true=y_test, y_pred=y_predicted2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27984    john presently with some he seems to have a gr...\n",
       "9637     to publish their and misfortunes except on the...\n",
       "3696     then several weeks elapsed before i saw the le...\n",
       "8325     the formation of a catalogue pen in hand wm ma...\n",
       "12886    friend extended pale and lifeless on the carpe...\n",
       "                               ...                        \n",
       "47704    idea tell him you mean to be your own counsel ...\n",
       "38997    its sunny day social social tendencies ths div...\n",
       "1915     the influence which he commanded had won him a...\n",
       "8756     short whenever they had nothing else to do â w...\n",
       "2554     whirl which drifted swiftly like a cloud on a ...\n",
       "Name: text, Length: 17714, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27984    26\n",
       "9637      8\n",
       "3696      8\n",
       "8325      8\n",
       "12886    12\n",
       "         ..\n",
       "47704    44\n",
       "38997    37\n",
       "1915      4\n",
       "8756      8\n",
       "2554      4\n",
       "Name: author, Length: 17714, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The position of the text in the data set: 12886\n",
      "The position of the text in the test set: 4\n",
      "\n",
      "Text:\n",
      "friend extended pale and lifeless on the carpet she turned on george with a furious face what have you been doing to the poor darling she demanded you she raised her hand to strike but caught her by the wrist i have been doing nothing he declared the rage of the she bear by the power of his glance miss bull fainted unexpectedly thank goodness here is some one it was one of the servants but waved her off no one but me â no one but me she cried and took the slender form of her friend up in her arms wait here she added to george i ll be down soon when she left the room george looked at the servant who was a quiet respectable old woman is that girl mad he asked she s queer poor soul sir replied the woman and entirely devoted to miss bull and well she may be for it is miss bull who the house the girl is a natural sir the red man she looks like it replied george sitting down you can go i shall wait here until miss bull yes sir the woman and departed but as she closed the door george heard her muttering something to herself the danger of s claws scratching him did not feel very comfortable on this point himself he saw that was a kind of animal who had been brought into by miss bull no other person could manage her and should she return still in a passion feared lest she should use physical violence still he held his ground as he was anxious to learn how the old maid was feeling and still more anxious to find out if possible why she had fainted on hearing his name i wonder if mrs told her anything muttered george as he looked out of the window but that s impossible mrs would keep her own secret so as to over besides miss bull declared that she recognized my face i wonder if she knew my father and if she can throw any light on the murder it is strange that she should be connected with the matter and in the same house as mrs upon my word said george in disgust it seems as though there were a gang of shady people here connected with my affairs and she was moved by the mention of s name i wonder what that meant but whatever it did mean he did not learn that day returned and stated that miss bull was better but was too faint to resume the conversation she begged mr to call another day gave this message in quite a friendly way and nodded to the astonished george you are better disposed toward me he said taking up his hat the yellow miss bull told me to be kind to you she declared still smiling and then with a burst of good nature i will be kind do you want to know about the papers if you choose to tell me said george but rejoicing at the opportunity this offered of learning something yes i do choose said she asked me to be kind to you well then tell me george her there was a lease in the green box and many bills said a few photographs and that was all i couldn t see the story what story miss nodded with a cunning smile and answered in a whisper as though her aunt was still and within hearing she told me it was a story she was writing oh such a long story sheets and sheets of a story â sheets she kept them in a long blue envelope and would not let me see them george reflected that evidently mrs had been writing out an account of her early life and s next words put the matter beyond a doubt my aunt said that she would let me have the story to read after she died but i could not find it in the green box perhaps you did not look thoroughly suggested george yes i did and i looked in all other places but i could not find it the story was italian went on staring at him for when my aunt wasn t looking i peeped san is in italy isn t it i believe so replied george more and more convinced that mrs had left a confession behind her did you tell miss bull the red man nodded she said i wasn t to say a word about it but she will not be angry at my telling you she likes you and says you are like some one she once knew and loved did not pursue the conversation he was afraid lest might say too much and miss bull might be angry and it was necessary that he should keep on good terms with miss bull evidently she had known his father she may even have loved him but george had heard so much that day that his brain was quite bewildered and he wanted to be alone to think the matter out only one last request he made of will you show me the photographs which were in the green box he asked i can t she replied drawing down her lip a child miss bull has them but she ll show them to you brightening for she likes you i like you too you are so handsome with a laugh and a blush at this compliment george left the house promising to call again with his head filled with many thoughts consequent on his two he emerged from square and walked down to oxford street a shout aroused him from his day dreams as he reached the corner he saw a tall red headed man crossing the road and a cab was bearing down on him the man stood in the and it was apparent that the horse would soon be on him \n",
      "\n",
      "Actual author: 12\n",
      "\n",
      "Prediction by MultinomialNB(): [8]\n",
      "\n",
      "Prediction by SGDClassifier(): [12]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "position = 4\n",
    "print(f'The position of the text in the data set: {X_test.index[position]}')\n",
    "print(f'The position of the text in the test set: {position}\\n')\n",
    "\n",
    "text = X_test.iloc[position]\n",
    "print(f'Text:\\n{text}\\n')\n",
    "\n",
    "actual_author = y_test.iloc[position]\n",
    "print(f'Actual author: {actual_author}\\n')\n",
    "\n",
    "\n",
    "text = [text]\n",
    "text_counts = count_vect.transform(text)\n",
    "text_tfidf = tfidf_transformer.transform(text_counts)\n",
    "#or\n",
    "#text_tfidf = X_test_tfidf[position]\n",
    "\n",
    "\n",
    "author_pred = clf.predict(text_tfidf)\n",
    "print(f'Prediction by MultinomialNB(): {author_pred}\\n')\n",
    "\n",
    "author_pred2 = clf2.predict(text_tfidf)\n",
    "print(f'Prediction by SGDClassifier(): {author_pred2}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used sources:\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "author",
   "language": "python",
   "name": "author"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
